{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b034440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrying out the imports.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_roc_curve, roc_auc_score, \\\n",
    "                            accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdab1d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38716, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>author</th>\n",
       "      <th>post</th>\n",
       "      <th>post_length</th>\n",
       "      <th>cleaned_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anger</td>\n",
       "      <td>aboowwabooww</td>\n",
       "      <td>I need help I have undiagnosed and untreated a...</td>\n",
       "      <td>1239</td>\n",
       "      <td>i need help i have undiagnosed and untreated a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anger</td>\n",
       "      <td>69andeverything</td>\n",
       "      <td>How can someone who doesn't get angry help my ...</td>\n",
       "      <td>772</td>\n",
       "      <td>how can someone who doesnt get angry help my b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anger</td>\n",
       "      <td>mailception</td>\n",
       "      <td>how I make it stop ? anyone please ? All I can...</td>\n",
       "      <td>1053</td>\n",
       "      <td>how i make it stop  anyone please  all i can e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anger</td>\n",
       "      <td>lemonsandrosemary</td>\n",
       "      <td>Shattered a Window Today Just like the title s...</td>\n",
       "      <td>376</td>\n",
       "      <td>shattered a window today just like the title s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anger</td>\n",
       "      <td>sadtimesecondary</td>\n",
       "      <td>I need help with my irritable depression \\nBas...</td>\n",
       "      <td>820</td>\n",
       "      <td>i need help with my irritable depression \\nbas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion             author  \\\n",
       "0   Anger       aboowwabooww   \n",
       "1   Anger    69andeverything   \n",
       "2   Anger        mailception   \n",
       "3   Anger  lemonsandrosemary   \n",
       "4   Anger   sadtimesecondary   \n",
       "\n",
       "                                                post  post_length  \\\n",
       "0  I need help I have undiagnosed and untreated a...         1239   \n",
       "1  How can someone who doesn't get angry help my ...          772   \n",
       "2  how I make it stop ? anyone please ? All I can...         1053   \n",
       "3  Shattered a Window Today Just like the title s...          376   \n",
       "4  I need help with my irritable depression \\nBas...          820   \n",
       "\n",
       "                                        cleaned_post  \n",
       "0  i need help i have undiagnosed and untreated a...  \n",
       "1  how can someone who doesnt get angry help my b...  \n",
       "2  how i make it stop  anyone please  all i can e...  \n",
       "3  shattered a window today just like the title s...  \n",
       "4  i need help with my irritable depression \\nbas...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read df.\n",
    "df = pd.read_csv('../datasets/final_df.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e122eff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion         0\n",
       "author          0\n",
       "post            0\n",
       "post_length     0\n",
       "cleaned_post    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null cells.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1cb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it's only 7 rows, I drop them.\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c80a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f47aad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating.\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f731b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining my X.\n",
    "df['lem_post'] = [lemmatizer.lemmatize(w) for w in df['cleaned_post']]\n",
    "X = df['lem_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c6f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning numerical values to my emotional classes for classification.\n",
    "df['emotion_cat'] = df['emotion'].map({'Anger' : 1, 'Disgust': 2, 'Fear': 3, 'Joy': 4, 'Neutral': 5, 'Sadness': 6, 'Surprise': 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ed522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c761204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining my y.\n",
    "y = df['emotion_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460937c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d1a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf562d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d67dc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(max_features = 500, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369681f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cvec = pd.DataFrame(\n",
    "    cvec.fit_transform(X_train).todense(),\n",
    "    columns = cvec.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844cba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cvec = pd.DataFrame(\n",
    "    cvec.transform(X_test).todense(),\n",
    "    columns = cvec.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "791b1bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>actually</th>\n",
       "      <th>advice</th>\n",
       "      <th>afraid</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>...</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>x200b</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  15  20  able  absolutely  actually  advice  afraid  age  ago  ...  \\\n",
       "0   0   0   0     0           0         0       0       0    0    0  ...   \n",
       "1   0   0   0     0           0         0       0       0    0    0  ...   \n",
       "2   0   0   0     0           0         0       0       0    0    0  ...   \n",
       "3   0   0   0     0           0         0       0       0    0    0  ...   \n",
       "4   0   0   0     0           0         0       0       0    0    0  ...   \n",
       "\n",
       "   wouldnt  writing  wrong  x200b  year  years  yesterday  youre  youtube  zen  \n",
       "0        0        0      0      0     0      0          0      0        0    0  \n",
       "1        0        0      0      0     0      0          0      0        0    0  \n",
       "2        0        0      0      0     0      0          0      0        0    0  \n",
       "3        0        0      0      0     0      0          0      0        0    0  \n",
       "4        0        0      0      0     0      0          0      0        0    0  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cvec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a9ced2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2134e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvec = pd.DataFrame(\n",
    "    tvec.fit_transform(X_train).todense(),\n",
    "    columns = tvec.get_feature_names()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb326a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tvec = pd.DataFrame(\n",
    "    tvec.transform(X_test).todense(),\n",
    "    columns = tvec.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d107b28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00009</th>\n",
       "      <th>001</th>\n",
       "      <th>0030</th>\n",
       "      <th>005</th>\n",
       "      <th>00s</th>\n",
       "      <th>01</th>\n",
       "      <th>010</th>\n",
       "      <th>...</th>\n",
       "      <th>zs</th>\n",
       "      <th>zshrc</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuhause</th>\n",
       "      <th>zuigan</th>\n",
       "      <th>zunsu</th>\n",
       "      <th>zuowang</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutang</th>\n",
       "      <th>zyprexa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  00009  001  0030  005  00s   01  010  ...   zs  zshrc  \\\n",
       "0  0.0  0.0   0.0    0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "1  0.0  0.0   0.0    0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "2  0.0  0.0   0.0    0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "3  0.0  0.0   0.0    0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "4  0.0  0.0   0.0    0.0  0.0   0.0  0.0  0.0  0.0  0.0  ...  0.0    0.0   \n",
       "\n",
       "   zuckerberg  zuhause  zuigan  zunsu  zuowang  zurich  zutang  zyprexa  \n",
       "0         0.0      0.0     0.0    0.0      0.0     0.0     0.0      0.0  \n",
       "1         0.0      0.0     0.0    0.0      0.0     0.0     0.0      0.0  \n",
       "2         0.0      0.0     0.0    0.0      0.0     0.0     0.0      0.0  \n",
       "3         0.0      0.0     0.0    0.0      0.0     0.0     0.0      0.0  \n",
       "4         0.0      0.0     0.0    0.0      0.0     0.0     0.0      0.0  \n",
       "\n",
       "[5 rows x 47024 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tvec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a6ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70da63d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15089    3\n",
       "26625    5\n",
       "27616    5\n",
       "16993    4\n",
       "28080    5\n",
       "        ..\n",
       "14185    3\n",
       "24262    5\n",
       "15869    3\n",
       "38540    7\n",
       "8364     2\n",
       "Name: emotion_cat, Length: 9678, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6e4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdaf1850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.194275\n",
       "3    0.174365\n",
       "1    0.164652\n",
       "4    0.139575\n",
       "6    0.125969\n",
       "7    0.116944\n",
       "2    0.084220\n",
       "Name: emotion_cat, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking distribution of y_train\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a59d3d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.194255\n",
       "3    0.174416\n",
       "1    0.164703\n",
       "4    0.139492\n",
       "6    0.125956\n",
       "7    0.116966\n",
       "2    0.084212\n",
       "Name: emotion_cat, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking distribution of y_test\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cfc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa88098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = DummyClassifier(random_state=42)\n",
    "baseline_model.fit(X_train_cvec, y_train)\n",
    "baseline_predictions = baseline_model.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b530874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19425501136598472"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, baseline_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb115f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19427508617564618"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(baseline_model,X_train_cvec,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa973a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bbdd4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd1989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train_cvec, y_train)\n",
    "dtree_predictions = dtree_model.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03709d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2429220913411862"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, dtree_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a9a4916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17825290240735703"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, dtree_predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6a86132f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24394605890084434"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dtree_model,X_train_cvec,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff42850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2420954742715437\n",
      "0.17724879369330307\n",
      "0.24363604665185762\n"
     ]
    }
   ],
   "source": [
    "dtree_model2 = DecisionTreeClassifier(max_depth = 2).fit(X_train_tvec, y_train)\n",
    "dtree_predictions2 = dtree_model2.predict(X_test_tvec)\n",
    "print(accuracy_score(y_test, dtree_predictions2))\n",
    "print(f1_score(y_test, dtree_predictions2, average='weighted'))\n",
    "print(cross_val_score(dtree_model2,X_train_tvec,y_train,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faeecd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca5494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4df92ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train_cvec, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc83e7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5645794585658194"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "228ecd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757793867132268"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, svm_predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfa05315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565016771840037"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm_model_linear,X_train_cvec,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear2 = SVC(kernel = 'linear', C = 1).fit(X_train_tvec, y_train)\n",
    "svm_predictions2 = svm_model_linear2.predict(X_test_tvec)\n",
    "print(accuracy_score(y_test, svm_predictions2))\n",
    "print(f1_score(y_test, svm_predictions2, average='weighted'))\n",
    "print(cross_val_score(svm_model_linear2,X_train_tvec,y_train,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae857ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69f77fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train_cvec, y_train)\n",
    "gnb_predictions = gnb.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1da4d5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43552386856788594"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, gnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f17c8941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45696437212933705"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, gnb_predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22542a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(gnb, X_train_cvec,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebf3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0479992-b1dc-4dd0-aada-e52ac0acbcfa",
   "metadata": {},
   "source": [
    "**Bert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a373836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\krispy\\anaconda3\\lib\\site-packages (4.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: requests in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.11)\n",
      "Requirement already satisfied: click in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\krispy\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235f4389-5d34-4366-add2-19a589bcba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bfc23b-187b-4e96-b164-7bcacad4f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4fb2a3-7b85-4829-836b-c38763ac23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8c22c-3602-4027-896a-efd1c22d8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied but don't know how to use this.\n",
    "dataset = tf.keras.utils.get_file(fname=\"aclImdb_v1.tar.gz\", \n",
    "                                  origin=URL,\n",
    "                                  untar=True,\n",
    "                                  cache_dir='.',\n",
    "                                  cache_subdir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e93298-373e-480e-a8d5-4dcb66938f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91facd-6890-4a83-aa58-cd4bdf2652ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f6eb8-6955-4267-b5ef-ce1a39323c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8a3db-6155-4a16-b87c-58b465426927",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d640fa-09cb-4f18-a191-01622f9c9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "labels = ['Negative','Positive']\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "for i in range(len(pred_sentences)):\n",
    "  print(pred_sentences[i], \": \\n\", labels[label[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a66f1-eacf-40d5-bf9e-4f4e2d669c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3624717c-491a-41f4-93f7-de187685d0a0",
   "metadata": {},
   "source": [
    "**Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3f73190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa696be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb42a9dbafa4466923aac6be47eb6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb780b59f5ea449a92b19f284941af5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111ad62d2dd043158997d518a50a850d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81dc173e39b42d1b761738ad6d6125e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea7606ceb2a4c1d976707a09bffcc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c7fd3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'sadness', 'score': 0.21333540976047516}, {'label': 'joy', 'score': 0.2224060595035553}, {'label': 'love', 'score': 0.0075500537641346455}, {'label': 'anger', 'score': 0.16987456381320953}, {'label': 'fear', 'score': 0.38217902183532715}, {'label': 'surprise', 'score': 0.004654841031879187}]]\n"
     ]
    }
   ],
   "source": [
    "prediction = classifier(\"i need help\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83275e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "423e3041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526954881dbd4d24a67adcc2d6ea0c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/935 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db8e246b4dc48b28b51a02005a6292d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bhadresh-savani/bert-base-uncased-emotion were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/bert-base-uncased-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd0f3b985d744a6933328ac09082cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/285 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c35c056fb6e43a7bda2f9ca17b4db7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d128970a284b68a8e68f223c55adb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08aff76daed24930984e1ae4059110c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/bert-base-uncased-emotion', return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f989355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'sadness', 'score': 0.21333540976047516}, {'label': 'joy', 'score': 0.2224060595035553}, {'label': 'love', 'score': 0.0075500537641346455}, {'label': 'anger', 'score': 0.16987456381320953}, {'label': 'fear', 'score': 0.38217902183532715}, {'label': 'surprise', 'score': 0.004654841031879187}]]\n"
     ]
    }
   ],
   "source": [
    "prediction = classifier(\"i need help\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3d969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
